import streamlit as st
try:
    import faiss
except ImportError:
    faiss = None
import json
import numpy as np
from sentence_transformers import SentenceTransformer
from openai import OpenAI

# ì„¸íŒ…
st.set_page_config(page_title="ê³ ìš©ë…¸ë™ë¶€ ë²•ë ¹í•´ì„ ê¸°ë°˜ RAG ì±—ë´‡", page_icon="ğŸ¤–")
st.title("ğŸ“š ê³ ìš©ë…¸ë™ë¶€ ë²•ë ¹í•´ì„ ê¸°ë°˜ RAG ì±—ë´‡")
st.caption("ğŸ” ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ê´€ë ¨ ì§ˆì˜Â·íšŒë‹µì„ ê²€ìƒ‰í•´ ë‹µë³€í•´ë“œë ¤ìš”.")

# ëª¨ë¸ ë° ë°ì´í„° ë¡œë”©
@st.cache_resource
def load_model_and_data():
    model = SentenceTransformer("all-MiniLM-L6-v2")
    with open("moel_sentences.json", encoding="utf-8") as f:
        sentences = json.load(f)
    index = faiss.read_index("moel_index.faiss")
    return model, sentences, index

model, sentences, index = load_model_and_data()

# ê²€ìƒ‰ í•¨ìˆ˜
def retrieve_similar_sentences(query, k=3):
    vec = model.encode([query], normalize_embeddings=True)
    D, I = index.search(np.array(vec), k)
    return [sentences[i] for i in I[0]]

# í”„ë¡¬í”„íŠ¸ êµ¬ì„± + GPT ì‘ë‹µ
client = OpenAI(api_key=st.secrets["openai"]["api_key"])

def build_prompt(query, docs):
    context = "\n---\n".join(docs)
    return f"""[ì‚¬ìš©ì ì§ˆë¬¸]
{query}

[ì°¸ê³  ë¬¸ì„œ]
{context}

â†’ ìœ„ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ë²•ë ¹ì— ê¸°ë°˜í•œ ì •í™•í•˜ê³  ê³µê° ìˆëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
"""

def detect_emotion(query: str) -> str:
    emotion_prompt = f"""
    ì•„ë˜ ì‚¬ìš©ì ë°œí™”ì—ì„œ ëŠê»´ì§€ëŠ” ì£¼ëœ ê°ì •ì„ ë‹¤ìŒ ì¤‘ì—ì„œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”: [ì¤‘ë¦½, ë¶ˆì•ˆ, ë¶„ë…¸, ìŠ¬í””, ì¢Œì ˆ, ê¸°ì¨]

    ë°œí™”: "{query}"

    ê°ì •:"""
    
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": emotion_prompt}]
    )
    emotion = response.choices[0].message.content.strip()
    return emotion

emotion_messages = {
    "ë¶ˆì•ˆ": "ì§€ê¸ˆ ëŠë¼ëŠ” ë¶ˆì•ˆì€ ë‹¹ì—°í•œ ê±°ì˜ˆìš”. í•¨ê»˜ í•´ê²° ë°©ë²•ì„ ì°¾ì•„ë“œë¦´ê²Œìš”.",
    "ë¶„ë…¸": "ë¶€ë‹¹í•œ ìƒí™©ì— ë¶„ë…¸í•˜ëŠ” ê±´ ë‹¹ì—°í•´ìš”. ì§€ê¸ˆë¶€í„° í•˜ë‚˜ì”© ì •ë¦¬í•´ë´ìš”.",
    "ìŠ¬í””": "ê·¸ë™ì•ˆ ì •ë§ í˜ë“œì…¨ì£ . ê´œì°®ì•„ìš”, ê³§ ë‚˜ì•„ì§ˆ ê±°ì˜ˆìš”.",
    "ì¢Œì ˆ": "ë„ˆë¬´ ì§€ì¹˜ì…¨ê² ì–´ìš”. ì´ì œ ë„ì›€ë°›ì„ ì‹œê°„ì´ì—ìš”.",
    "ê¸°ì¨": "ì¢‹ì€ ì†Œì‹ì´ë„¤ìš”! í•¨ê»˜ ê¸°ë»ìš”",
    "ì¤‘ë¦½": "",
}


def gpt_answer(prompt):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content.strip()

# ë©”ì¸ ì¸í„°í˜ì´ìŠ¤
query = st.text_input("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: í”„ë¡œì íŠ¸ ì¢…ë£Œ ì‹œì ì„ ê³„ì•½ ê¸°ê°„ìœ¼ë¡œ ì ì–´ë„ ë˜ë‚˜ìš”?")

if query:
    with st.spinner("ğŸ” ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„± ì¤‘..."):
        docs = retrieve_similar_sentences(query)
        prompt = build_prompt(query, docs)
        answer = gpt_answer(prompt)
        emotion = detect_emotion(query)

    st.markdown("### ğŸ¤– ì±—ë´‡ì˜ ë‹µë³€")
    st.success(answer)

    # ê°ì„± ì¼€ì–´ ë©”ì‹œì§€ ì¶”ê°€ ì¶œë ¥
    if emotion in emotion_messages and emotion_messages[emotion]:
        st.info(f"ğŸ’Œ {emotion_messages[emotion]}")

    with st.expander("ğŸ“„ RAG ì°¸ê³  ë¬¸ì„œ ë³´ê¸°"):
        for i, doc in enumerate(docs, 1):
            st.markdown(f"**ë¬¸ì„œ {i}**\n\n{doc}")